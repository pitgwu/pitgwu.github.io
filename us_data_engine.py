import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import datetime
import time
import re
from io import StringIO
# âœ¨ å¼•å…¥ Google å®˜æ–¹æœ€æ–° SDK
from google import genai
from google.genai import types

# ==========================================
# 0. å…¨åŸŸè¨­å®šèˆ‡ç›®éŒ„æº–å‚™
# ==========================================
NOW = datetime.datetime.now()
YYYY = NOW.strftime("%Y")
MM = NOW.strftime("%m")
DATE_STR = NOW.strftime("%Y%m%d")

BASE_DIR = "us_stock_dashboard"
TARGET_DIR = os.path.join(BASE_DIR, YYYY, MM)

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(TARGET_DIR, exist_ok=True)

print(f"ğŸ“‚ ç›®æ¨™è³‡æ–™å¤¾: {TARGET_DIR}")
print(f"ğŸ“… è™•ç†æ—¥æœŸ: {DATE_STR}")

# å–å¾— API Key (å»ºè­°è¨­å®šåœ¨ç’°å¢ƒè®Šæ•¸)
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ==========================================
# 1. éœæ…‹è§€å¯Ÿåå–® (æ ¸å¿ƒæ¬Šå€¼è‚¡ & æŒ‡æ•¸)
# ==========================================
STATIC_TICKERS = {
    # --- æŒ‡æ•¸ ---
    "^DJI": {"Name": "Dow Jones", "Theme": "Index"},
    "^GSPC": {"Name": "S&P 500", "Theme": "Index"},
    "^IXIC": {"Name": "Nasdaq", "Theme": "Index"},
    "^SOX": {"Name": "PHLX Semi", "Theme": "Index"},
    "^VIX": {"Name": "VIX", "Theme": "Index"},
    "BTC-USD": {"Name": "Bitcoin", "Theme": "Crypto"},
    # --- âœ¨ [æ–°å¢] åŸç‰©æ–™ (Commodities) ---
    "GC=F": {"Name": "Gold (é»ƒé‡‘)", "Theme": "Commodity"},
    "SI=F": {"Name": "Silver (ç™½éŠ€)", "Theme": "Commodity"},
    "HG=F": {"Name": "Copper (éŠ…)", "Theme": "Commodity"},
    "HRC=F": {"Name": "Steel (ç†±è»‹é‹¼)", "Theme": "Commodity"},
    "CL=F": {"Name": "Crude Oil (åŸæ²¹)", "Theme": "Commodity"}, # é †ä¾¿é€æ‚¨åŸæ²¹ï¼Œé€šå¸¸æœƒä¸€èµ·çœ‹
    
    # --- ç§‘æŠ€å·¨é ­ ---
    "NVDA": {"Name": "NVIDIA", "Theme": "Technology"},
    "MSFT": {"Name": "Microsoft", "Theme": "Technology"},
    "AAPL": {"Name": "Apple", "Theme": "Technology"},
    "AMZN": {"Name": "Amazon", "Theme": "Consumer Cyclical"},
    "GOOG": {"Name": "Alphabet", "Theme": "Communication Services"},
    "META": {"Name": "Meta", "Theme": "Communication Services"},
    "TSLA": {"Name": "Tesla", "Theme": "Consumer Cyclical"},
    
    # --- åŠå°é«”èˆ‡ç†±é–€è‚¡ ---
    "TSM": {"Name": "TSMC", "Theme": "Technology"},
    "AMD": {"Name": "AMD", "Theme": "Technology"},
    "AVGO": {"Name": "Broadcom", "Theme": "Technology"},
    "SMCI": {"Name": "Super Micro", "Theme": "Technology"},
    "COIN": {"Name": "Coinbase", "Theme": "Financial"},
}

# åˆå§‹åŒ–å…¨åŸŸè³‡è¨Šå­—å…¸
ALL_TICKER_INFO = STATIC_TICKERS.copy()

# ==========================================
# 2. åŠŸèƒ½æ¨¡çµ„ï¼šæŠ“å–å¸‚å ´æƒ…ç·’ (Fear & Greed)
# ==========================================
def fetch_fear_and_greed():
    print("æ­£åœ¨æŠ“å– CNN Fear & Greed æŒ‡æ•¸...")
    
    # å½è£æˆç€è¦½å™¨ Header
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://edition.cnn.com/"
    }
    
    result = None

    # æ–¹æ³• A: å˜—è©¦å®˜æ–¹ API
    try:
        url_api = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        resp = requests.get(url_api, headers=headers, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            latest = data['fear_and_greed']
            rating = latest['rating'].capitalize() if latest['rating'] else "Neutral"
            result = {"score": int(latest['score']), "rating": rating, "timestamp": latest['timestamp']}
            print(f"âœ… [API] CNN æŒ‡æ•¸ç²å–æˆåŠŸ: {result['score']}")
    except: pass

    # æ–¹æ³• B: å˜—è©¦çˆ¬ç¶²é  (Regex)
    if result is None:
        try:
            url_web = "https://edition.cnn.com/markets/fear-and-greed"
            resp = requests.get(url_web, headers=headers, timeout=10)
            if resp.status_code == 200:
                match_score = re.search(r'"score":([\d\.]+)', resp.text)
                match_rating = re.search(r'"rating":"([a-zA-Z\s]+)"', resp.text)
                if match_score:
                    score = int(float(match_score.group(1)))
                    rating = match_rating.group(1).capitalize() if match_rating else "Neutral"
                    result = {"score": score, "rating": rating, "timestamp": datetime.datetime.now().isoformat()}
                    print(f"âœ… [Web] CNN æŒ‡æ•¸ç²å–æˆåŠŸ: {result['score']}")
        except: pass

    # å­˜æª”
    filepath = os.path.join(TARGET_DIR, f"sentiment_{DATE_STR}.json")
    if result:
        with open(filepath, "w", encoding="utf-8") as f: json.dump(result, f, indent=4)
    else:
        print("âŒ CNN æŒ‡æ•¸ç²å–å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼")
        with open(filepath, "w", encoding="utf-8") as f: json.dump({"score": 50, "rating": "N/A", "timestamp": ""}, f)

# ==========================================
# 3. åŠŸèƒ½æ¨¡çµ„ï¼šå‹•æ…‹å¸‚å ´æƒæ (Yahoo çˆ¬èŸ²)
# ==========================================
def get_market_screeners():
    """ çˆ¬å– Yahoo Finance ç¶²é æŠ“å–ç•¶æ—¥æœ€ç†±é–€èˆ‡æ¼²å¹…æœ€å¤§è‚¡ç¥¨ """
    print("ğŸ” æ­£åœ¨çˆ¬å– Yahoo ç¶²é ç†±é–€æ¦œ...")
    
    targets = [
        ("https://finance.yahoo.com/most-active", "Most Active"),
        ("https://finance.yahoo.com/gainers", "Top Gainers")
    ]
    
    found_tickers = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}

    for url, tag in targets:
        try:
            r = requests.get(url, headers=headers, timeout=10)
            # ä½¿ç”¨ StringIO é¿å… Pandas FutureWarning
            dfs = pd.read_html(StringIO(r.text))
            
            if len(dfs) > 0:
                df = dfs[0]
                symbols = df.iloc[:, 0].tolist()
                
                count = 0
                for sym in symbols:
                    sym = str(sym).split(" ")[0] # å»é™¤è¨»è§£
                    # éæ¿¾æ‰åŒ…å« . çš„æ¬Šè­‰æˆ–éé•·çš„ä»£è™Ÿ
                    if "." not in sym and len(sym) < 6:
                        found_tickers.append(sym)
                        # å¦‚æœä¸åœ¨éœæ…‹åå–®ä¸­ï¼Œæš«æ™‚æ¨™è¨˜ï¼Œç¨å¾ŒæœƒæŠ“è©³ç´° Sector
                        if sym not in ALL_TICKER_INFO:
                            ALL_TICKER_INFO[sym] = {"Name": sym, "Theme": "Unknown"}
                        count += 1
                print(f"   -> {tag}: æŠ“åˆ° {count} æª”")
        except Exception as e:
            print(f"   âš ï¸ çˆ¬å–å¤±æ•— {url}: {e}")

    # ä¿åº•æ©Ÿåˆ¶ï¼šå¦‚æœçˆ¬èŸ²å…¨æ›ï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®
    if not found_tickers:
        print("âš ï¸ è­¦å‘Šï¼šçˆ¬èŸ²æœªæŠ“åˆ°æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨ç†±é–€æ¸…å–®")
        backup = ["PLTR", "SOFI", "MARA", "RIOT", "DKNG", "UBER", "HOOD", "OPEN", "LCID", "RIVN", "AMD", "F", "BAC"]
        for sym in backup:
            if sym not in ALL_TICKER_INFO: ALL_TICKER_INFO[sym] = {"Name": sym, "Theme": "Backup"}
        found_tickers = backup

    return list(set(found_tickers))

# ==========================================
# 4. åŠŸèƒ½æ¨¡çµ„ï¼šç²å–å€‹è‚¡æ–°èèˆ‡åˆ†é¡
# ==========================================
def get_stock_profile(ticker_obj, symbol):
    """ é€é yfinance API ç²å– Sector èˆ‡ Industry """
    try:
        # ç‰¹æ®Šè™•ç†
        if symbol == "BTC-USD": return "Crypto", "Cryptocurrency"
        if symbol.startswith("^"): return "Index", "Market Index"
        
        info = ticker_obj.info
        sector = info.get('sector', 'Other')
        industry = info.get('industry', 'Other')
        return sector, industry
    except:
        return "Other", "Other"


def calculate_technicals(closes):
    """ è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼šRSI, MAç‹€æ…‹ """
    try:
        if len(closes) < 15: return "è³‡æ–™ä¸è¶³", 50

        # 1. è¨ˆç®— RSI (14)
        delta = closes.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        current_rsi = round(rsi.iloc[-1], 1)

        # 2. è¨ˆç®—å‡ç·šèˆ‡ä¹–é›¢
        ma5 = closes.rolling(window=5).mean().iloc[-1]
        ma20 = closes.rolling(window=20).mean().iloc[-1]
        price = closes.iloc[-1]

        # 3. ç”Ÿæˆæè¿°å­—ä¸²
        trend = ""
        if price > ma5 and price > ma20: trend = "å¤šé ­æ’åˆ— (ç«™ä¸Š5æ—¥/20æ—¥ç·š)"
        elif price < ma5 and price < ma20: trend = "ç©ºé ­æ’åˆ— (è·Œç ´5æ—¥/20æ—¥ç·š)"
        elif price > ma20: trend = "æ”¯æ’æœ‰å®ˆ (ç«™ä¸Š20æ—¥ç·š)"
        else: trend = "æ•´ç†æ ¼å±€"

        tech_summary = f"RSI(14)={current_rsi}, {trend}, 5æ—¥ä¹–é›¢={(price/ma5-1)*100:.1f}%"
        return tech_summary, current_rsi
    except:
        return "æŠ€è¡“é¢æ•¸æ“šè¨ˆç®—å¤±æ•—", 50


def get_stock_news(symbol):
    """ ä½¿ç”¨ yfinance æŠ“å–è©²è‚¡ç¥¨çš„æœ€æ–°æ–°èæ¨™é¡Œ """
    try:
        t = yf.Ticker(symbol)
        news_list = t.news
        headlines = []
        if news_list:
            for n in news_list[:5]: # å–å‰ 5 å‰‡
                headlines.append(f"- {n.get('title', '')}")
        return "\n".join(headlines)
    except:
        return "No recent news found."

# ==========================================
# 5. åŠŸèƒ½æ¨¡çµ„ï¼šGemini AI åˆ†æ (æ–°ç‰ˆ SDK) - ä¿®æ­£ç‰ˆ
# ==========================================
def generate_ai_analysis(df_daily):
    """ æŒ‘é¸ Top 10 é£†è‚¡ä¸¦å‘¼å« Gemini 2.0 Flash-Lite é€²è¡Œåˆ†æ """
    print("\nğŸ¤– æ­£åœ¨å•Ÿå‹• Google Gemini AI åˆ†ææ¨¡çµ„ (Ver 2.0 Lite)...")
    
    if not GOOGLE_API_KEY:
        print("âš ï¸ è·³é AI åˆ†æ (ç¼ºå°‘ API Key)")
        return

    try:
        client = genai.Client(api_key=GOOGLE_API_KEY)
    except Exception as e:
        print(f"âš ï¸ Gemini Client åˆå§‹åŒ–å¤±æ•—: {e}")
        return

    try:
        # 1. æŒ‘é¸åå–® (Top 10)
        df_liquid = df_daily.sort_values(by='Daily_Amount_B', ascending=False).head(50)
        top_gainers = df_liquid.sort_values(by='Daily_Chg%', ascending=False).head(10)
        
        if top_gainers.empty:
            return

        ai_data = []

        for i, (_, row) in enumerate(top_gainers.iterrows()):
            symbol = row['Code']
            name = row['Name']
            chg = row['Daily_Chg%']
            sector = row['Sector']
            
            print(f"   -> [{i+1}/10] åˆ†æ: {symbol} ({chg}%) | è¯ç¶²æœå°‹ä¸­...")
            
            # --- æŠ€è¡“æŒ‡æ¨™ ---
            try:
                hist = yf.download(symbol, period="1mo", progress=False, auto_adjust=False)
                if not hist.empty:
                    if isinstance(hist.columns, pd.MultiIndex):
                        close_series = hist['Close'][symbol]
                    else:
                        close_series = hist['Close']
                    tech_str, rsi_val = calculate_technicals(close_series)
                else:
                    tech_str, rsi_val = "ç„¡æŠ€è¡“æ•¸æ“š", 50
            except:
                tech_str, rsi_val = "æ•¸æ“šè®€å–éŒ¯èª¤", 50

            # --- Prompt ---
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¯çˆ¾è¡—ç¾è‚¡åˆ†æå¸«ã€‚è«‹åˆ†æç¾è‚¡ {symbol} ({name})ã€‚
            ä»Šæ—¥æ¼²å¹…ï¼š{chg}%
            æ‰€å±¬æ¿å¡Šï¼š{sector}
            æŠ€è¡“é¢æ•¸æ“šï¼š{tech_str}
            
            è«‹åˆ©ç”¨ Google Search æœå°‹è©²å…¬å¸ã€Œä»Šæ—¥æœ€æ–°è²¡ç¶“æ–°èã€ã€ã€Œæœ€è¿‘ä¸€é€±é‡å¤§å…¬å‘Šã€ä»¥åŠã€Œå°ç£ä¾›æ‡‰éˆé—œä¿‚ã€ã€‚
            
            è«‹å›å‚³ä¸€å€‹ã€ç´” JSON å­—ä¸²ã€‘ï¼Œä¸è¦åŒ…å« Markdown (```json ... ```) æ¨™è¨˜ã€‚
            JSON æ ¼å¼å¦‚ä¸‹ï¼š
            {{
                "position": "ä¸€å¥è©±ç²¾æº–æè¿°å®ƒè³£ä»€éº¼ç”¢å“ã€å¸‚ä½”ç‡æˆ–é—œéµåœ°ä½ (30å­—å…§)",
                "catalyst": "ä¸Šæ¼²å…·é«”åŸå› ã€‚æ˜¯è²¡å ±å„ªæ–¼é æœŸ(çµ¦æ•¸å­—)ï¼Ÿåˆ†æå¸«å‡è©•ï¼Ÿé‚„æ˜¯ç™¼å¸ƒæ–°ç”¢å“ï¼Ÿ (40å­—å…§)",
                "momentum": "çµåˆæŠ€è¡“é¢æ•¸æ“š ({tech_str}) èˆ‡æœå°‹çµæœçš„å‹•èƒ½åˆ¤æ–· (30å­—å…§)",
                "taiwan_link": "åˆ—å‡º 2-3 æª”å—æƒ çš„å°ç£ä¾›æ‡‰éˆåç¨±èˆ‡ä»£è™Ÿï¼Œä¸¦ç”¨æ‹¬è™Ÿèªªæ˜é—œä¿‚"
            }}
            """

            try:
                # âœ¨ [æ•‘æ´] æ”¹ç”¨ Lite ç‰ˆæœ¬ï¼Œé¿é–‹å·²è€—ç›¡çš„é…é¡
                response = client.models.generate_content(
                    model='gemini-2.0-flash-lite-preview-02-05', 
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        # é—œé–‰ JSON Mode ä»¥æ”¯æ´ Google Search Tool
                        tools=[types.Tool(google_search=types.GoogleSearch())]
                    )
                )
                
                # æ‰‹å‹•æ¸…ç† JSON å­—ä¸²
                raw_text = response.text
                clean_text = raw_text.replace("```json", "").replace("```", "").strip()
                
                analysis = json.loads(clean_text)
                
                ai_data.append({
                    "symbol": symbol,
                    "name": name,
                    "chg": chg,
                    "analysis": analysis
                })
                print(f"      âœ… åˆ†æå®Œæˆ (RSI: {rsi_val})")
                
                # è¯ç¶²æœå°‹è€—æ™‚ï¼Œä¼‘æ¯ 10 ç§’
                time.sleep(10)
                
            except Exception as e:
                # æ•æ‰ 429 éŒ¯èª¤ (Resource Exhausted)
                if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                    print(f"      âŒ é…é¡è€—ç›¡ï¼Œåœæ­¢å¾ŒçºŒåˆ†æã€‚")
                    break # ç›´æ¥è·³å‡ºè¿´åœˆï¼Œä¸å†å˜—è©¦ä¸‹ä¸€æª”
                
                print(f"      âš ï¸ Gemini åˆ†æå¤±æ•—: {e}")
                # Fallback
                ai_data.append({
                    "symbol": symbol, "name": name, "chg": chg,
                    "analysis": {
                        "position": "è³‡æ–™è®€å–ä¸­...", "catalyst": "AI é€£ç·šé€¾æ™‚ï¼Œè«‹åƒé–±æ–°è",
                        "momentum": f"æŠ€è¡“é¢ï¼š{tech_str}", "taiwan_link": "æš«ç„¡æ³•æŸ¥è©¢"
                    }
                })
                time.sleep(15)

        # å­˜æª”
        out_path = os.path.join(TARGET_DIR, f"ai_report_{DATE_STR}.json")
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(ai_data, f, ensure_ascii=False, indent=4)
        print(f"âœ… AI åˆ†æå ±å‘Šå·²ç”Ÿæˆ: {out_path}")

    except Exception as e:
        print(f"âŒ AI æ¨¡çµ„åŸ·è¡ŒéŒ¯èª¤: {e}")

# ==========================================
# 6. ä¸»ç¨‹å¼ï¼šæ•¸æ“šä¸‹è¼‰èˆ‡è™•ç†
# ==========================================
def fetch_and_process_data():
    # 1. æŠ“æƒ…ç·’
    fetch_fear_and_greed()
    
    # 2. æŠ“å‹•æ…‹æ¸…å–®
    dynamic_tickers = get_market_screeners()
    
    # 3. åˆä½µæ¸…å–®
    static_list = list(STATIC_TICKERS.keys())
    final_tickers = list(set(static_list + dynamic_tickers))
    
    print(f"ğŸš€ æº–å‚™ä¸‹è¼‰ {len(final_tickers)} æª”æ•¸æ“šä¸¦åˆ†æç”¢æ¥­çµæ§‹...")
    
    results = []
    
    # åˆ†æ‰¹è¨­å®š (é¿å… Timeout)
    BATCH_SIZE = 8
    chunks = [final_tickers[i:i + BATCH_SIZE] for i in range(0, len(final_tickers), BATCH_SIZE)]
    
    for i, chunk in enumerate(chunks):
        max_retries = 5
        success = False
        data = pd.DataFrame()

        # é‡è©¦è¿´åœˆ
        for attempt in range(max_retries):
            try:
                print(f"â³ ä¸‹è¼‰æ‰¹æ¬¡ {i+1}/{len(chunks)}: {chunk[:3]}...")
                # threads=False æ˜¯é¿å…å¤§é‡é€£ç·šè¢«é˜»æ“‹çš„é—œéµ
                data = yf.download(chunk, period="3mo", progress=False, auto_adjust=False, threads=False)
                if not data.empty:
                    success = True
                    break
            except: 
                time.sleep(2)
            time.sleep(2) # å¤±æ•—å¾Œç­‰å¾…

        if not success or data.empty:
            print(f"âŒ æ‰¹æ¬¡ {i+1} å¤±æ•—ï¼Œè·³é")
            continue
        
        # è™•ç†è©²æ‰¹æ¬¡æ•¸æ“š
        for ticker in chunk:
            try:
                # è™•ç† yfinance å›å‚³æ ¼å¼ (å–®æª” vs å¤šæª”)
                if len(chunk) == 1 or isinstance(data.columns, pd.Index) and not isinstance(data.columns, pd.MultiIndex):
                    closes = data['Close']; volumes = data['Volume']
                else:
                    try: 
                        closes = data['Close'][ticker].dropna()
                        volumes = data['Volume'][ticker].dropna()
                    except: continue

                if closes.empty: continue
                current_price = closes.iloc[-1]
                
                # éæ¿¾è‚¡åƒ¹ä½æ–¼ $1 çš„æ°´é¤ƒè‚¡
                if current_price < 1.0: continue

                current_vol = 0 if volumes.empty else volumes.iloc[-1]
                
                # è¨ˆç®— RVOL (ç›¸å°æˆäº¤é‡)
                rvol = 0
                if len(volumes) >= 6:
                    avg_vol_5d = volumes.iloc[-6:-1].mean()
                    rvol = (current_vol / avg_vol_5d) if avg_vol_5d > 0 else 0

                # è¨ˆç®—æ¼²è·Œå¹…
                def calc_chg(s, shift):
                    if len(s) > shift:
                        prev = s.iloc[-(shift + 1)]
                        return ((s.iloc[-1] - prev) / prev) * 100 if prev != 0 else 0
                    return 0
                
                daily_chg = calc_chg(closes, 1)
                amount_b = (current_price * current_vol) / 1_000_000_000
                
                # --- ã€é—œéµã€‘ç²å– Sector & Industry ---
                t_obj = yf.Ticker(ticker)
                sector, industry = get_stock_profile(t_obj, ticker)
                
                # å–å¾—åç¨± (å„ªå…ˆä½¿ç”¨æˆ‘å€‘æ¸…å–®ä¸­çš„ï¼Œè‹¥ç„¡å‰‡ç”¨ä»£è™Ÿ)
                name = ALL_TICKER_INFO.get(ticker, {}).get('Name', ticker)

                results.append({
                    "Code": ticker,
                    "Name": name,
                    "Sector": sector,     # ç¬¬ä¸€å±¤åˆ†é¡
                    "Industry": industry, # ç¬¬äºŒå±¤åˆ†é¡
                    "Close": round(current_price, 2),
                    "Volume": current_vol,
                    "RVOL": round(rvol, 2),
                    "Daily_Chg%": round(daily_chg, 2),
                    "Weekly_Chg%": round(calc_chg(closes, 5), 2),
                    "Monthly_Chg%": round(calc_chg(closes, 21), 2),
                    "Daily_Amount_B": round(amount_b, 2),
                    "Weekly_Amount_B": round(amount_b, 2), # é€™è£¡ç°¡åŒ–ï¼Œç”¨ç•¶æ—¥é‡ä»£è¡¨
                    "Monthly_Amount_B": round(amount_b, 2)
                })

            except Exception as e: continue
        
        # æ‰¹æ¬¡é–“ä¼‘æ¯
        time.sleep(1)

    # å­˜æª”
    if results:
        df = pd.DataFrame(results)
        df['Sector'] = df.fillna('Other')['Sector']
        df['Industry'] = df.fillna('Other')['Industry']
        
        # å„²å­˜ CSV
        for fname in [f"rank_daily_{DATE_STR}.csv", f"rank_weekly_{DATE_STR}.csv", f"rank_monthly_{DATE_STR}.csv"]:
            csv_path = os.path.join(TARGET_DIR, fname)
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # ã€åŸ·è¡Œ Gemini AI åˆ†æã€‘
        # åªå‚³å…¥æ—¥æ’è¡Œæ•¸æ“š
        # generate_ai_analysis(df)
        
        print(f"\nâœ… æ•¸æ“šæ›´æ–°å®Œæˆï¼æ‰€æœ‰æª”æ¡ˆå·²æ­¸æª”è‡³: {TARGET_DIR}")
    else:
        print("âŒ åš´é‡éŒ¯èª¤ï¼šæœªæŠ“å–åˆ°ä»»ä½•æœ‰æ•ˆæ•¸æ“š")

if __name__ == "__main__":
    fetch_and_process_data()
