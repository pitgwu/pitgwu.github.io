import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import datetime

# ==========================================
# 0. è¨­å®šèˆ‡ç›®éŒ„æº–å‚™
# ==========================================
# å–å¾—ä»Šæ—¥æ—¥æœŸèˆ‡è·¯å¾‘è³‡è¨Š
NOW = datetime.datetime.now()
YYYY = NOW.strftime("%Y")
MM = NOW.strftime("%m")
DATE_STR = NOW.strftime("%Y%m%d")

# å®šç¾©æ ¹ç›®éŒ„èˆ‡ç›®æ¨™ç›®éŒ„: us_stock_dashboard/2026/01
BASE_DIR = "us_stock_dashboard"
TARGET_DIR = os.path.join(BASE_DIR, YYYY, MM)

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(TARGET_DIR, exist_ok=True)

print(f"ğŸ“‚ ç›®æ¨™è³‡æ–™å¤¾: {TARGET_DIR}")
print(f"ğŸ“… è™•ç†æ—¥æœŸ: {DATE_STR}")

# ==========================================
# 1. è‚¡ç¥¨åŸºæœ¬è³‡æ–™è¨­å®š
# ==========================================
TICKER_INFO = {
    # --- ç§‘æŠ€å·¨é ­ ---
    "NVDA": {"Name": "NVIDIA", "Theme": "AI é¾é ­"},
    "MSFT": {"Name": "Microsoft", "Theme": "è»Ÿé«”/é›²ç«¯"},
    "AAPL": {"Name": "Apple", "Theme": "æ¶ˆè²»é›»å­"},
    "AMZN": {"Name": "Amazon", "Theme": "é›»å•†/AWS"},
    "GOOG": {"Name": "Alphabet", "Theme": "æœå°‹å¼•æ“"},
    "META": {"Name": "Meta", "Theme": "ç¤¾ç¾¤/å»£å‘Š"},
    "TSLA": {"Name": "Tesla", "Theme": "é›»å‹•è»Š"},
    
    # --- åŠå°é«” ---
    "TSM":  {"Name": "TSMC", "Theme": "æ™¶åœ“ä»£å·¥"},
    "AVGO": {"Name": "Broadcom", "Theme": "ç¶²é€š/ASIC"},
    "AMD":  {"Name": "AMD", "Theme": "CPU/GPU"},
    "INTC": {"Name": "Intel", "Theme": "åŠå°é«”"},
    "MU":   {"Name": "Micron", "Theme": "è¨˜æ†¶é«”"},
    "QCOM": {"Name": "Qualcomm", "Theme": "æ‰‹æ©Ÿæ™¶ç‰‡"},
    "TXN":  {"Name": "Texas Inst", "Theme": "é¡æ¯”IC"},
    "AMAT": {"Name": "Applied Mat", "Theme": "è¨­å‚™"},
    "LRCX": {"Name": "Lam Research", "Theme": "è¨­å‚™"},
    "SMCI": {"Name": "Super Micro", "Theme": "ä¼ºæœå™¨"},
    
    # --- è»Ÿé«”/è³‡å®‰/é‡‘è ---
    "ORCL": {"Name": "Oracle", "Theme": "è³‡æ–™åº«"},
    "ADBE": {"Name": "Adobe", "Theme": "å‰µæ„è»Ÿé«”"},
    "CRM":  {"Name": "Salesforce", "Theme": "CRM"},
    "CRWD": {"Name": "CrowdStrike", "Theme": "è³‡å®‰"},
    "PLTR": {"Name": "Palantir", "Theme": "å¤§æ•¸æ“š/AI"},
    "PANW": {"Name": "Palo Alto", "Theme": "è³‡å®‰"},
    "JPM":  {"Name": "JPMorgan", "Theme": "éŠ€è¡Œé¾é ­"},
    "V":    {"Name": "Visa", "Theme": "æ”¯ä»˜"},
    "MA":   {"Name": "Mastercard", "Theme": "æ”¯ä»˜"},
    "PYPL": {"Name": "PayPal", "Theme": "æ”¯ä»˜"},
    "COIN": {"Name": "Coinbase", "Theme": "åŠ å¯†äº¤æ˜“æ‰€"},
    "MSTR": {"Name": "MicroStrategy", "Theme": "æ¯”ç‰¹å¹£æŒå€‰"},

    # --- å‚³çµ±/æ¶ˆè²»/å…¶ä»– ---
    "WMT":  {"Name": "Walmart", "Theme": "é›¶å”®é¾é ­"},
    "COST": {"Name": "Costco", "Theme": "é‡è²©"},
    "LLY":  {"Name": "Eli Lilly", "Theme": "æ¸›è‚¥è—¥"},
    "JNJ":  {"Name": "J&J", "Theme": "é†«ç™‚ä¿å¥"},
    "NFLX": {"Name": "Netflix", "Theme": "ä¸²æµ"},
    "DIS":  {"Name": "Disney", "Theme": "å¨›æ¨‚"},
    "XOM":  {"Name": "Exxon Mobil", "Theme": "çŸ³æ²¹"},
    
    # --- æŒ‡æ•¸ ---
    "BTC-USD": {"Name": "Bitcoin", "Theme": "åŠ å¯†è²¨å¹£"},
    "^VIX":    {"Name": "VIX Index", "Theme": "ææ…ŒæŒ‡æ•¸"}
}

ALL_TICKERS = list(TICKER_INFO.keys())

def fetch_fear_and_greed():
    """ æŠ“å– CNN ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸ """
    print("æ­£åœ¨æŠ“å– CNN Fear & Greed æŒ‡æ•¸...")
    url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            latest_data = data['fear_and_greed']
            score = int(latest_data['score'])
            rating = latest_data['rating']
            timestamp = latest_data['timestamp']
            
            result = {
                "score": score,
                "rating": rating,
                "timestamp": timestamp
            }
            
            # å­˜æª”è·¯å¾‘ï¼šåŠ ä¸Šæ—¥æœŸå¾Œç¶´ï¼Œä¸¦å­˜å…¥ç›®æ¨™è³‡æ–™å¤¾
            filename = f"sentiment_{DATE_STR}.json"
            filepath = os.path.join(TARGET_DIR, filename)
            
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=4)
            
            print(f"âœ… CNN æŒ‡æ•¸å·²å­˜æª”: {filepath}")
            return result
        else:
            print(f"âš ï¸ CNN API å›å‚³éŒ¯èª¤: {response.status_code}")
            return None
    except Exception as e:
        print(f"âš ï¸ CNN æŒ‡æ•¸æŠ“å–å¤±æ•—: {e}")
        # å¤±æ•—æ™‚çš„é è¨­æª”æ¡ˆ
        default_data = {"score": 50, "rating": "Neutral (Data N/A)", "timestamp": ""}
        filename = f"sentiment_{DATE_STR}.json"
        filepath = os.path.join(TARGET_DIR, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(default_data, f)
        return None

def fetch_and_process_data():
    fetch_fear_and_greed()
    
    print(f"æ­£åœ¨ä¸‹è¼‰ {len(ALL_TICKERS)} æª”æ¨™çš„æ•¸æ“š (ç¯„åœ: 3å€‹æœˆ)...")
    
    try:
        data = yf.download(ALL_TICKERS, period="3mo", progress=False, auto_adjust=False)
        
        results = []

        for ticker in ALL_TICKERS:
            try:
                closes = data['Close'][ticker].dropna()
                try:
                    volumes = data['Volume'][ticker].dropna()
                except KeyError:
                    volumes = pd.Series()

                if closes.empty: continue
                
                current_price = closes.iloc[-1]
                current_vol = 0 if volumes.empty else volumes.iloc[-1]
                
                def calc_dynamic_change(series, shift_count):
                    if len(series) > shift_count:
                        last_val = series.iloc[-1]
                        prev_val = series.iloc[-(shift_count + 1)]
                        if prev_val == 0: return 0.0
                        return ((last_val - prev_val) / prev_val) * 100
                    return 0.0

                daily_chg = calc_dynamic_change(closes, 1)
                weekly_chg = calc_dynamic_change(closes, 5)
                monthly_chg = calc_dynamic_change(closes, 21)
                amount_b = (current_price * current_vol) / 1_000_000_000
                info = TICKER_INFO.get(ticker, {"Name": ticker, "Theme": "N/A"})

                results.append({
                    "Code": ticker,
                    "Name": info['Name'],
                    "Theme": info['Theme'],
                    "Close": round(current_price, 2),
                    "Volume": current_vol,
                    "Daily_Chg%": round(daily_chg, 2),
                    "Daily_Amount_B": round(amount_b, 2),
                    "Weekly_Chg%": round(weekly_chg, 2),
                    "Weekly_Amount_B": round(amount_b, 2),
                    "Monthly_Chg%": round(monthly_chg, 2),
                    "Monthly_Amount_B": round(amount_b, 2)
                })

            except Exception as e:
                continue

        df_result = pd.DataFrame(results)
        
        # å®šç¾©è¼¸å‡ºçš„ä¸‰å€‹ CSV æª”å (å«æ—¥æœŸ)
        csv_files = [
            f"rank_daily_{DATE_STR}.csv",
            f"rank_weekly_{DATE_STR}.csv",
            f"rank_monthly_{DATE_STR}.csv"
        ]
        
        for fname in csv_files:
            filepath = os.path.join(TARGET_DIR, fname)
            df_result.to_csv(filepath, index=False, encoding='utf-8-sig')
            print(f"å·²å„²å­˜: {filepath}")

        print(f"\nâœ… æ•¸æ“šæ›´æ–°å®Œæˆï¼æ‰€æœ‰æª”æ¡ˆå·²æ­¸æª”è‡³: {TARGET_DIR}")
        
    except Exception as e:
        print(f"ä¸‹è¼‰æµç¨‹éŒ¯èª¤: {e}")

if __name__ == "__main__":
    fetch_and_process_data()
