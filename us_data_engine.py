import yfinance as yf
import pandas as pd
import numpy as np
import requests
import json
import os
import datetime
import time
import re
from io import StringIO

# ==========================================
# 0. è¨­å®šèˆ‡ç›®éŒ„æº–å‚™
# ==========================================
NOW = datetime.datetime.now()
YYYY = NOW.strftime("%Y")
MM = NOW.strftime("%m")
DATE_STR = NOW.strftime("%Y%m%d")

BASE_DIR = "us_stock_dashboard"
TARGET_DIR = os.path.join(BASE_DIR, YYYY, MM)

os.makedirs(TARGET_DIR, exist_ok=True)

print(f"ğŸ“‚ ç›®æ¨™è³‡æ–™å¤¾: {TARGET_DIR}")
print(f"ğŸ“… è™•ç†æ—¥æœŸ: {DATE_STR}")

# ==========================================
# 1. éœæ…‹è§€å¯Ÿåå–® (æ ¸å¿ƒæ¬Šå€¼è‚¡ & æŒ‡æ•¸)
# ==========================================
# é€™äº›æ˜¯ç„¡è«–æœ‰ç„¡ä¸Šæ¦œï¼Œæˆ‘å€‘éƒ½æƒ³æŒçºŒç›£æ§çš„æ¨™çš„
STATIC_TICKERS = {
    # æŒ‡æ•¸
    "^DJI": {"Name": "Dow Jones", "Theme": "Index"},
    "^GSPC": {"Name": "S&P 500", "Theme": "Index"},
    "^IXIC": {"Name": "Nasdaq", "Theme": "Index"},
    "^SOX": {"Name": "PHLX Semi", "Theme": "Index"},
    "^VIX": {"Name": "VIX", "Theme": "Index"},
    "BTC-USD": {"Name": "Bitcoin", "Theme": "Crypto"},
    
    # ç§‘æŠ€å·¨é ­
    "NVDA": {"Name": "NVIDIA", "Theme": "Technology"},
    "MSFT": {"Name": "Microsoft", "Theme": "Technology"},
    "AAPL": {"Name": "Apple", "Theme": "Technology"},
    "AMZN": {"Name": "Amazon", "Theme": "Consumer Cyclical"},
    "GOOG": {"Name": "Alphabet", "Theme": "Communication Services"},
    "META": {"Name": "Meta", "Theme": "Communication Services"},
    "TSLA": {"Name": "Tesla", "Theme": "Consumer Cyclical"},
    
    # åŠå°é«”èˆ‡ç†±é–€è‚¡
    "TSM": {"Name": "TSMC", "Theme": "Technology"},
    "AMD": {"Name": "AMD", "Theme": "Technology"},
    "AVGO": {"Name": "Broadcom", "Theme": "Technology"},
    "SMCI": {"Name": "Super Micro", "Theme": "Technology"},
    "COIN": {"Name": "Coinbase", "Theme": "Financial"},
}

# åˆå§‹åŒ–å…¨åŸŸè³‡è¨Šå­—å…¸
ALL_TICKER_INFO = STATIC_TICKERS.copy()

# ==========================================
# 2. åŠŸèƒ½å‡½å¼ï¼šæŠ“å–ææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸
# ==========================================
def fetch_fear_and_greed():
    print("æ­£åœ¨æŠ“å– CNN Fear & Greed æŒ‡æ•¸...")
    
    # å½è£ Header
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    result = None

    # æ–¹æ³• A: å˜—è©¦ API
    try:
        url_api = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        resp = requests.get(url_api, headers=headers, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            latest = data['fear_and_greed']
            rating = latest['rating'].capitalize() if latest['rating'] else "Neutral"
            result = {"score": int(latest['score']), "rating": rating, "timestamp": latest['timestamp']}
            print(f"âœ… [API] CNN æŒ‡æ•¸ç²å–æˆåŠŸ: {result['score']}")
    except: pass

    # æ–¹æ³• B: å˜—è©¦çˆ¬ç¶²é  (å‚™æ¡ˆ)
    if result is None:
        try:
            url_web = "https://edition.cnn.com/markets/fear-and-greed"
            resp = requests.get(url_web, headers=headers, timeout=10)
            if resp.status_code == 200:
                match_score = re.search(r'"score":([\d\.]+)', resp.text)
                match_rating = re.search(r'"rating":"([a-zA-Z\s]+)"', resp.text)
                if match_score:
                    score = int(float(match_score.group(1)))
                    rating = match_rating.group(1).capitalize() if match_rating else "Neutral"
                    result = {"score": score, "rating": rating, "timestamp": datetime.datetime.now().isoformat()}
                    print(f"âœ… [Web] CNN æŒ‡æ•¸ç²å–æˆåŠŸ: {result['score']}")
        except: pass

    # å­˜æª”
    filepath = os.path.join(TARGET_DIR, f"sentiment_{DATE_STR}.json")
    if result:
        with open(filepath, "w", encoding="utf-8") as f: json.dump(result, f, indent=4)
    else:
        print("âŒ CNN æŒ‡æ•¸ç²å–å¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼")
        with open(filepath, "w", encoding="utf-8") as f: json.dump({"score": 50, "rating": "N/A", "timestamp": ""}, f)

# ==========================================
# 3. åŠŸèƒ½å‡½å¼ï¼šå‹•æ…‹å¸‚å ´æƒæ (Web Scraping)
# ==========================================
def get_market_screeners():
    """ çˆ¬å– Yahoo Finance ç¶²é æŠ“å–ç•¶æ—¥æœ€ç†±é–€èˆ‡æ¼²å¹…æœ€å¤§è‚¡ç¥¨ """
    print("ğŸ” æ­£åœ¨çˆ¬å– Yahoo ç¶²é ç†±é–€æ¦œ...")
    
    targets = [
        ("https://finance.yahoo.com/most-active", "Most Active"),
        ("https://finance.yahoo.com/gainers", "Top Gainers")
    ]
    
    found_tickers = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}

    for url, tag in targets:
        try:
            r = requests.get(url, headers=headers, timeout=10)
            # ä½¿ç”¨ StringIO é¿å… Pandas è­¦å‘Š
            dfs = pd.read_html(StringIO(r.text))
            
            if len(dfs) > 0:
                df = dfs[0]
                symbols = df.iloc[:, 0].tolist()
                
                count = 0
                for sym in symbols:
                    sym = str(sym).split(" ")[0] # è™•ç†è¨»è§£
                    # éæ¿¾æ¬Šè­‰æˆ–ä¸å°‹å¸¸çš„ä»£è™Ÿ
                    if "." not in sym and len(sym) < 6:
                        found_tickers.append(sym)
                        # å¦‚æœä¸åœ¨éœæ…‹åå–®ä¸­ï¼Œæš«æ™‚æ¨™è¨˜ï¼Œç¨å¾ŒæœƒæŠ“è©³ç´° Sector
                        if sym not in ALL_TICKER_INFO:
                            ALL_TICKER_INFO[sym] = {"Name": sym, "Theme": "Unknown"}
                        count += 1
                print(f"   -> {tag}: æŠ“åˆ° {count} æª”")
        except Exception as e:
            print(f"   âš ï¸ çˆ¬å–å¤±æ•— {url}: {e}")

    # ä¿åº•æ©Ÿåˆ¶ï¼šå¦‚æœçˆ¬èŸ²å…¨æ›ï¼Œä½¿ç”¨å‚™ç”¨æ¸…å–®
    if not found_tickers:
        print("âš ï¸ è­¦å‘Šï¼šçˆ¬èŸ²æœªæŠ“åˆ°æ•¸æ“šï¼Œä½¿ç”¨å‚™ç”¨ç†±é–€æ¸…å–®")
        backup = ["PLTR", "SOFI", "MARA", "RIOT", "DKNG", "UBER", "HOOD", "OPEN", "LCID", "RIVN", "AMD", "F", "BAC"]
        for sym in backup:
            if sym not in ALL_TICKER_INFO: ALL_TICKER_INFO[sym] = {"Name": sym, "Theme": "Backup"}
        found_tickers = backup

    return list(set(found_tickers))

# ==========================================
# 4. åŠŸèƒ½å‡½å¼ï¼šç²å– Sector èˆ‡ Industry
# ==========================================
def get_stock_profile(ticker_obj, symbol):
    """ é€é yfinance API ç²å–è©³ç´°åˆ†é¡ """
    try:
        # ç‰¹æ®Šè™•ç†
        if symbol == "BTC-USD": return "Crypto", "Cryptocurrency"
        if symbol.startswith("^"): return "Index", "Market Index"
        
        info = ticker_obj.info
        sector = info.get('sector', 'Other')
        industry = info.get('industry', 'Other')
        return sector, industry
    except:
        return "Other", "Other"

# ==========================================
# 5. ä¸»ç¨‹å¼ï¼šä¸‹è¼‰èˆ‡è™•ç†æ•¸æ“š
# ==========================================
def fetch_and_process_data():
    # 1. æŠ“æƒ…ç·’
    fetch_fear_and_greed()
    
    # 2. æŠ“å‹•æ…‹æ¸…å–®
    dynamic_tickers = get_market_screeners()
    
    # 3. åˆä½µæ¸…å–®
    static_list = list(STATIC_TICKERS.keys())
    final_tickers = list(set(static_list + dynamic_tickers))
    
    print(f"ğŸš€ æº–å‚™ä¸‹è¼‰ {len(final_tickers)} æª”æ•¸æ“šä¸¦åˆ†æç”¢æ¥­çµæ§‹...")
    
    results = []
    
    # åˆ†æ‰¹è¨­å®š (é¿å… Timeout)
    BATCH_SIZE = 8
    chunks = [final_tickers[i:i + BATCH_SIZE] for i in range(0, len(final_tickers), BATCH_SIZE)]
    
    for i, chunk in enumerate(chunks):
        max_retries = 5
        success = False
        data = pd.DataFrame()

        # é‡è©¦è¿´åœˆ
        for attempt in range(max_retries):
            try:
                print(f"â³ ä¸‹è¼‰æ‰¹æ¬¡ {i+1}/{len(chunks)}: {chunk[:3]}...")
                # threads=False æ˜¯é¿å…å¤§é‡é€£ç·šè¢«é˜»æ“‹çš„é—œéµ
                data = yf.download(chunk, period="3mo", progress=False, auto_adjust=False, threads=False)
                if not data.empty:
                    success = True
                    break
            except: 
                time.sleep(2)
            time.sleep(2) # å¤±æ•—å¾Œç­‰å¾…

        if not success or data.empty:
            print(f"âŒ æ‰¹æ¬¡ {i+1} å¤±æ•—ï¼Œè·³é")
            continue
        
        # è™•ç†è©²æ‰¹æ¬¡æ•¸æ“š
        for ticker in chunk:
            try:
                # è™•ç† yfinance å›å‚³æ ¼å¼ (å–®æª” vs å¤šæª”)
                if len(chunk) == 1 or isinstance(data.columns, pd.Index) and not isinstance(data.columns, pd.MultiIndex):
                    closes = data['Close']; volumes = data['Volume']
                else:
                    try: 
                        closes = data['Close'][ticker].dropna()
                        volumes = data['Volume'][ticker].dropna()
                    except: continue

                if closes.empty: continue
                current_price = closes.iloc[-1]
                
                # éæ¿¾è‚¡åƒ¹ä½æ–¼ $1 çš„æ°´é¤ƒè‚¡
                if current_price < 1.0: continue

                current_vol = 0 if volumes.empty else volumes.iloc[-1]
                
                # è¨ˆç®— RVOL (ç›¸å°æˆäº¤é‡)
                rvol = 0
                if len(volumes) >= 6:
                    avg_vol_5d = volumes.iloc[-6:-1].mean()
                    rvol = (current_vol / avg_vol_5d) if avg_vol_5d > 0 else 0

                # è¨ˆç®—æ¼²è·Œå¹…
                def calc_chg(s, shift):
                    if len(s) > shift:
                        prev = s.iloc[-(shift + 1)]
                        return ((s.iloc[-1] - prev) / prev) * 100 if prev != 0 else 0
                    return 0
                
                daily_chg = calc_chg(closes, 1)
                amount_b = (current_price * current_vol) / 1_000_000_000
                
                # --- ã€é—œéµã€‘ç²å– Sector & Industry ---
                t_obj = yf.Ticker(ticker)
                sector, industry = get_stock_profile(t_obj, ticker)
                
                # å–å¾—åç¨± (å„ªå…ˆä½¿ç”¨æˆ‘å€‘æ¸…å–®ä¸­çš„ï¼Œè‹¥ç„¡å‰‡ç”¨ä»£è™Ÿ)
                name = ALL_TICKER_INFO.get(ticker, {}).get('Name', ticker)

                results.append({
                    "Code": ticker,
                    "Name": name,
                    "Sector": sector,     # ç¬¬ä¸€å±¤åˆ†é¡
                    "Industry": industry, # ç¬¬äºŒå±¤åˆ†é¡
                    "Close": round(current_price, 2),
                    "Volume": current_vol,
                    "RVOL": round(rvol, 2),
                    "Daily_Chg%": round(daily_chg, 2),
                    "Weekly_Chg%": round(calc_chg(closes, 5), 2),
                    "Monthly_Chg%": round(calc_chg(closes, 21), 2),
                    "Daily_Amount_B": round(amount_b, 2),
                    "Weekly_Amount_B": round(amount_b, 2), # é€™è£¡ç°¡åŒ–ï¼Œç”¨ç•¶æ—¥é‡ä»£è¡¨
                    "Monthly_Amount_B": round(amount_b, 2)
                })

            except Exception as e: continue
        
        # æ‰¹æ¬¡é–“ä¼‘æ¯
        time.sleep(1)

    # å­˜æª”
    if results:
        df_result = pd.DataFrame(results)
        # å¡«è£œç©ºç¼º
        df_result['Sector'] = df_result['Sector'].fillna('Other')
        df_result['Industry'] = df_result['Industry'].fillna('Other')
        
        for fname in [f"rank_daily_{DATE_STR}.csv", f"rank_weekly_{DATE_STR}.csv", f"rank_monthly_{DATE_STR}.csv"]:
            df_result.to_csv(os.path.join(TARGET_DIR, fname), index=False, encoding='utf-8-sig')
        print(f"\nâœ… æ•¸æ“šæ›´æ–°å®Œæˆï¼å·²åŒ…å« Sector èˆ‡ Industry è³‡è¨Šã€‚")
    else:
        print("âŒ åš´é‡éŒ¯èª¤ï¼šæœªæŠ“å–åˆ°ä»»ä½•æœ‰æ•ˆæ•¸æ“š")

if __name__ == "__main__":
    fetch_and_process_data()
